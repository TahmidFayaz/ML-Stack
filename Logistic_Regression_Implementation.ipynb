{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "yWqsNoZvxknT"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Steps\n",
        "\n"
      ],
      "metadata": {
        "id": "n81nXfNiAco1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training :\n",
        "\n",
        "1) Intialize weights as 0\n",
        "\n",
        "2) Intialize bias as 0\n",
        "\n",
        "3) Predict result using *y* = 1/1+ e^(-wx+b)\n",
        "\n",
        "4) Calculate Error\n",
        "\n",
        "5) Use gradient descent to figure out new weight and bias values as it keeps updating\n",
        "\n",
        "6) Repeat n times"
      ],
      "metadata": {
        "id": "Bu7983vQAkGX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def sigmoid(x):\n",
        "  return 1/(1+np.exp(-x))\n",
        "\n",
        "class Logistic_Regression():\n",
        "  def __init__(self,lr=0.001,iter=1000):\n",
        "    self.lr=lr\n",
        "    self.iter=iter\n",
        "    self.weight=None\n",
        "    self.bias=None\n",
        "\n",
        "  def fit(self,x,y):\n",
        "    n_samples,n_features=x.shape\n",
        "    self.weight=np.zeros(n_features)\n",
        "    self.bias=0\n",
        "\n",
        "\n",
        "  #For training the model\n",
        "  #Gradient Descent\n",
        "\n",
        "    for i in range(self.iter):\n",
        "      linear_model=np.dot(x,self.weight)+self.bias\n",
        "      predictions= sigmoid(linear_model)\n",
        "\n",
        "      #Gradient/Error Calculation\n",
        "\n",
        "      dw=(1/n_samples)*np.dot(x.T,(predictions-y))\n",
        "      db=(1/n_samples)*np.sum(predictions-y)\n",
        "\n",
        "      #Updating weights and bias\n",
        "\n",
        "      self.weight-=self.lr*dw\n",
        "      self.bias-=self.lr*db\n",
        "\n",
        "  #Training Done,now time to predict on newly,unseen data\n",
        "\n",
        "  def predict(self,x):\n",
        "      linear_model=np.dot(x,self.weight)+self.bias\n",
        "      y_pred= sigmoid(linear_model)\n",
        "      class_pred=[]\n",
        "      for i in y_pred:\n",
        "        if i <= 0.5:\n",
        "          class_pred.append(0)\n",
        "        else:\n",
        "          class_pred.append(1)\n",
        "      return class_pred\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "2HFyFnXk_irR"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "z=w\n",
        "1\n",
        "​\n",
        " x\n",
        "1\n",
        "​\n",
        " +w\n",
        "2\n",
        "​\n",
        " x\n",
        "2\n",
        "​\n",
        " +…+w\n",
        "n\n",
        "​\n",
        " x\n",
        "n\n",
        "​\n",
        " +b\n",
        "\n",
        "\n",
        "\n",
        " Here w1,w2,w3 are coefficients or weights and b is the bias\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        " def fit (self,x,y):\n",
        "\n",
        "  here\n",
        "  x=features/ 2D Array / row =sample ,col=feature\n",
        "  y=1D array (output)\n",
        "\n",
        "\n",
        "  self.weight=np.zeroes(n_features)--->\n",
        "\n",
        "  coefficents gulo ke 0 diye initiallize korbo\n",
        "  For example, if your data has 3 features (like height, weight, and age), np.zeros(n_features) would create an array like [0.0, 0.0, 0.0].\n",
        "  equal to the number of cols\n",
        "\n",
        "The zero initialization means the model starts with no bias toward any input feature\n",
        "\n",
        "linear_model=np.dot(x,self.weight)+self.bias ------>>\n",
        "\n",
        "y\n",
        "i\n",
        "=\n",
        "β\n",
        "0\n",
        "+\n",
        "β\n",
        "1\n",
        "x\n",
        "i\n",
        ",\n",
        "1\n",
        "+\n",
        "β\n",
        "2\n",
        "x\n",
        "i\n",
        ",\n",
        "2\n",
        "+\n",
        "…\n",
        "+\n",
        "β\n",
        "k\n",
        "x\n",
        "i\n",
        ",\n",
        "k\n",
        "+\n",
        "ϵ\n",
        "i\n",
        ".\n",
        "\n",
        "\n",
        "\n",
        "Then we insert the y i in sigmoid function\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "y_pred = LR.predict(X_test): Uses the trained model to make predictions on the test data.\n",
        "\n",
        "\n",
        "accuracy(y_pred, y_test): Custom function to compute accuracy by comparing the predicted labels (y_pred) to the true labels (y_test).\n",
        "  \n"
      ],
      "metadata": {
        "id": "j682PLBsLxFh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train\n"
      ],
      "metadata": {
        "id": "5ucFlkLTTc9n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bc = datasets.load_breast_cancer()\n",
        "bc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BMdfZZDHE_86",
        "outputId": "ccb09cca-fa2b-436d-f6ce-a31a0a093006"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'data': array([[1.799e+01, 1.038e+01, 1.228e+02, ..., 2.654e-01, 4.601e-01,\n",
              "         1.189e-01],\n",
              "        [2.057e+01, 1.777e+01, 1.329e+02, ..., 1.860e-01, 2.750e-01,\n",
              "         8.902e-02],\n",
              "        [1.969e+01, 2.125e+01, 1.300e+02, ..., 2.430e-01, 3.613e-01,\n",
              "         8.758e-02],\n",
              "        ...,\n",
              "        [1.660e+01, 2.808e+01, 1.083e+02, ..., 1.418e-01, 2.218e-01,\n",
              "         7.820e-02],\n",
              "        [2.060e+01, 2.933e+01, 1.401e+02, ..., 2.650e-01, 4.087e-01,\n",
              "         1.240e-01],\n",
              "        [7.760e+00, 2.454e+01, 4.792e+01, ..., 0.000e+00, 2.871e-01,\n",
              "         7.039e-02]]),\n",
              " 'target': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0,\n",
              "        1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "        1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
              "        0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1,\n",
              "        1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0,\n",
              "        0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0,\n",
              "        1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1,\n",
              "        1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0,\n",
              "        0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0,\n",
              "        0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n",
              "        1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1,\n",
              "        1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1,\n",
              "        1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
              "        1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
              "        1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1,\n",
              "        1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1]),\n",
              " 'frame': None,\n",
              " 'target_names': array(['malignant', 'benign'], dtype='<U9'),\n",
              " 'DESCR': '.. _breast_cancer_dataset:\\n\\nBreast cancer wisconsin (diagnostic) dataset\\n--------------------------------------------\\n\\n**Data Set Characteristics:**\\n\\n    :Number of Instances: 569\\n\\n    :Number of Attributes: 30 numeric, predictive attributes and the class\\n\\n    :Attribute Information:\\n        - radius (mean of distances from center to points on the perimeter)\\n        - texture (standard deviation of gray-scale values)\\n        - perimeter\\n        - area\\n        - smoothness (local variation in radius lengths)\\n        - compactness (perimeter^2 / area - 1.0)\\n        - concavity (severity of concave portions of the contour)\\n        - concave points (number of concave portions of the contour)\\n        - symmetry\\n        - fractal dimension (\"coastline approximation\" - 1)\\n\\n        The mean, standard error, and \"worst\" or largest (mean of the three\\n        worst/largest values) of these features were computed for each image,\\n        resulting in 30 features.  For instance, field 0 is Mean Radius, field\\n        10 is Radius SE, field 20 is Worst Radius.\\n\\n        - class:\\n                - WDBC-Malignant\\n                - WDBC-Benign\\n\\n    :Summary Statistics:\\n\\n    ===================================== ====== ======\\n                                           Min    Max\\n    ===================================== ====== ======\\n    radius (mean):                        6.981  28.11\\n    texture (mean):                       9.71   39.28\\n    perimeter (mean):                     43.79  188.5\\n    area (mean):                          143.5  2501.0\\n    smoothness (mean):                    0.053  0.163\\n    compactness (mean):                   0.019  0.345\\n    concavity (mean):                     0.0    0.427\\n    concave points (mean):                0.0    0.201\\n    symmetry (mean):                      0.106  0.304\\n    fractal dimension (mean):             0.05   0.097\\n    radius (standard error):              0.112  2.873\\n    texture (standard error):             0.36   4.885\\n    perimeter (standard error):           0.757  21.98\\n    area (standard error):                6.802  542.2\\n    smoothness (standard error):          0.002  0.031\\n    compactness (standard error):         0.002  0.135\\n    concavity (standard error):           0.0    0.396\\n    concave points (standard error):      0.0    0.053\\n    symmetry (standard error):            0.008  0.079\\n    fractal dimension (standard error):   0.001  0.03\\n    radius (worst):                       7.93   36.04\\n    texture (worst):                      12.02  49.54\\n    perimeter (worst):                    50.41  251.2\\n    area (worst):                         185.2  4254.0\\n    smoothness (worst):                   0.071  0.223\\n    compactness (worst):                  0.027  1.058\\n    concavity (worst):                    0.0    1.252\\n    concave points (worst):               0.0    0.291\\n    symmetry (worst):                     0.156  0.664\\n    fractal dimension (worst):            0.055  0.208\\n    ===================================== ====== ======\\n\\n    :Missing Attribute Values: None\\n\\n    :Class Distribution: 212 - Malignant, 357 - Benign\\n\\n    :Creator:  Dr. William H. Wolberg, W. Nick Street, Olvi L. Mangasarian\\n\\n    :Donor: Nick Street\\n\\n    :Date: November, 1995\\n\\nThis is a copy of UCI ML Breast Cancer Wisconsin (Diagnostic) datasets.\\nhttps://goo.gl/U2Uwz2\\n\\nFeatures are computed from a digitized image of a fine needle\\naspirate (FNA) of a breast mass.  They describe\\ncharacteristics of the cell nuclei present in the image.\\n\\nSeparating plane described above was obtained using\\nMultisurface Method-Tree (MSM-T) [K. P. Bennett, \"Decision Tree\\nConstruction Via Linear Programming.\" Proceedings of the 4th\\nMidwest Artificial Intelligence and Cognitive Science Society,\\npp. 97-101, 1992], a classification method which uses linear\\nprogramming to construct a decision tree.  Relevant features\\nwere selected using an exhaustive search in the space of 1-4\\nfeatures and 1-3 separating planes.\\n\\nThe actual linear program used to obtain the separating plane\\nin the 3-dimensional space is that described in:\\n[K. P. Bennett and O. L. Mangasarian: \"Robust Linear\\nProgramming Discrimination of Two Linearly Inseparable Sets\",\\nOptimization Methods and Software 1, 1992, 23-34].\\n\\nThis database is also available through the UW CS ftp server:\\n\\nftp ftp.cs.wisc.edu\\ncd math-prog/cpo-dataset/machine-learn/WDBC/\\n\\n|details-start|\\n**References**\\n|details-split|\\n\\n- W.N. Street, W.H. Wolberg and O.L. Mangasarian. Nuclear feature extraction \\n  for breast tumor diagnosis. IS&T/SPIE 1993 International Symposium on \\n  Electronic Imaging: Science and Technology, volume 1905, pages 861-870,\\n  San Jose, CA, 1993.\\n- O.L. Mangasarian, W.N. Street and W.H. Wolberg. Breast cancer diagnosis and \\n  prognosis via linear programming. Operations Research, 43(4), pages 570-577, \\n  July-August 1995.\\n- W.H. Wolberg, W.N. Street, and O.L. Mangasarian. Machine learning techniques\\n  to diagnose breast cancer from fine-needle aspirates. Cancer Letters 77 (1994) \\n  163-171.\\n\\n|details-end|',\n",
              " 'feature_names': array(['mean radius', 'mean texture', 'mean perimeter', 'mean area',\n",
              "        'mean smoothness', 'mean compactness', 'mean concavity',\n",
              "        'mean concave points', 'mean symmetry', 'mean fractal dimension',\n",
              "        'radius error', 'texture error', 'perimeter error', 'area error',\n",
              "        'smoothness error', 'compactness error', 'concavity error',\n",
              "        'concave points error', 'symmetry error',\n",
              "        'fractal dimension error', 'worst radius', 'worst texture',\n",
              "        'worst perimeter', 'worst area', 'worst smoothness',\n",
              "        'worst compactness', 'worst concavity', 'worst concave points',\n",
              "        'worst symmetry', 'worst fractal dimension'], dtype='<U23'),\n",
              " 'filename': 'breast_cancer.csv',\n",
              " 'data_module': 'sklearn.datasets.data'}"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Gqi4Gk_UHIa5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "bc = datasets.load_breast_cancer()\n",
        "X, y = bc.data, bc.target\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
        "\n",
        "# Instantiate the Logistic Regression model\n",
        "LR = Logistic_Regression(lr=0.01, iter=1000)\n",
        "\n",
        "# Train the model on the training data\n",
        "LR.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test data\n",
        "y_pred = LR.predict(X_test)\n",
        "\n",
        "# Define the accuracy function\n",
        "def accuracy(y_pred, y_test):\n",
        "    return np.sum(y_pred == y_test) / len(y_test)\n",
        "\n",
        "\n",
        "acc = accuracy(y_pred, y_test)\n",
        "print(f\"Accuracy: {acc * 100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DQqIc_MfTewQ",
        "outputId": "3ea1677d-1daa-4840-f005-c07068370ac1"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 95.61%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-13-58b78d86b117>:2: RuntimeWarning: overflow encountered in exp\n",
            "  return 1/(1+np.exp(-x))\n"
          ]
        }
      ]
    }
  ]
}